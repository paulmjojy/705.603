{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization: How to Maintain Model Accuracy While Reducing the Size of the Model\n",
    "\n",
    "Below you will find code related to the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.applications import mobilenet_v2, resnet_v2\n",
    "from tensorflow.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.keras as k\n",
    "from keras.applications import imagenet_utils\n",
    "import glob\n",
    "import re\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below functions are related to loading the images/labels into memory, generating architecture for the networks, and predicting the accuracy for the non-quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)\n",
    "IMG_SHAPE= IMG_SIZE + (3,)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#load images and labels from directory\n",
    "def load_imgs(path):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    files = glob.glob(path+'*.JPEG')\n",
    "    for f in files:\n",
    "        # load an image in PIL format\n",
    "        original = k.preprocessing.image.load_img(f, target_size=IMG_SIZE)    \n",
    "        # convert the PIL image to a numpy array    \n",
    "        numpy_image = k.preprocessing.image.img_to_array(original)\n",
    "        labels.append(re.search('_(.+)\\.',f).group(1))\n",
    "        imgs.append(numpy_image)\n",
    "    return imgs, labels\n",
    "\n",
    "#generate architecture for pretrained model initialized with imagenet weights\n",
    "def generate_model(modeltype):\n",
    "    inputs = k.Input(shape=(224,224,3))\n",
    "    x = imagenet_utils.preprocess_input(inputs, data_format=None, mode='tf')\n",
    "    if modeltype == 'mobilenet':\n",
    "        outputs = mobilenet_v2.MobileNetV2(input_shape=IMG_SHAPE,weights='imagenet')(x)\n",
    "    elif modeltype == 'resnet50':\n",
    "        outputs = resnet_v2.ResNet50V2(input_shape=IMG_SHAPE,weights='imagenet')(x)            \n",
    "    elif modeltype == 'resnet101':\n",
    "        outputs = resnet_v2.ResNet101V2(input_shape=IMG_SHAPE,weights='imagenet')(x)            \n",
    "    else:\n",
    "        outputs = resnet_v2.ResNet152V2(input_shape=IMG_SHAPE,weights='imagenet')(x)         \n",
    "            \n",
    "    model = k.Model(inputs,outputs)\n",
    "    #save model for size analysis\n",
    "    model.save('models/'+modeltype+'.h5')\n",
    "    return model\n",
    "\n",
    "#predict classes for images\n",
    "def predict_class(images,model):\n",
    "    predictions = model.predict(images)        \n",
    "    labels = k.applications.imagenet_utils.decode_predictions(predictions)\n",
    "    labels = [label[0][1] for label in labels]\n",
    "    return labels\n",
    "\n",
    "#Prints accuracy\n",
    "def accuracy(preds, actual):\n",
    "    accuracy = (sum(x == y for x,y in zip(preds,actual))/len(preds))*100\n",
    "    print('model accuracy is %.2f%% (Number of test samples=%d)' % (accuracy, len(preds)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all helper functions set up for the non-quantized model, below we will set up functions for running the quantized model, which is no longer a keras model. It is a TFlite binary. These functions were built with the help of TensorFlow tutorial here: https://www.tensorflow.org/lite/performance/post_training_integer_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_quant_model, test_image_indices):\n",
    "\n",
    "    # Initialize the interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    predictions = []\n",
    "    for i, test_image_index in enumerate(test_image_indices):\n",
    "        test_image = imgs[test_image_index]\n",
    "        test_label = labels[test_image_index]\n",
    "\n",
    "        # Check if the input type is quantized, then rescale input data to uint8\n",
    "        if input_details['dtype'] == np.uint8:\n",
    "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "            test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "        interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "        predictions.append(output)\n",
    "    return predictions\n",
    "\n",
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_model(tflite_model):\n",
    "    test_image_indices = range(len(imgs))\n",
    "    predictions = run_tflite_model(tflite_model, test_image_indices)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    predictions = k.applications.imagenet_utils.decode_predictions(predictions)\n",
    "    predictions = [preds[0][1] for preds in predictions]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "#Dynamic range quantization function\n",
    "def dynamic_range_quant(model,modeltype):\n",
    "    quant_file_path = 'quant_models/dynamic'+modeltype+'.tflite'\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_quant_model = converter.convert()\n",
    "    \n",
    "    with open(quant_file_path, 'wb') as f:\n",
    "        f.write(tflite_quant_model)\n",
    "    return tflite_quant_model\n",
    "\n",
    "#Calibration dataset generator\n",
    "def representative_dataset():\n",
    "    for data in tf.data.Dataset.from_tensor_slices((imgs)).batch(1).take(1000):\n",
    "        yield [data]\n",
    "        \n",
    "#Full integer quantization function\n",
    "def full_int_quant(model,modeltype):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    # Ensure that if any ops can't be quantized, the converter throws an error\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    # Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "\n",
    "    tflite_quant_model = converter.convert()\n",
    "    \n",
    "    quant_file_path = 'quant_models/fullint'+modeltype+'.tflite'\n",
    "    with open(quant_file_path, 'wb') as f:\n",
    "        f.write(tflite_quant_model)\n",
    "\n",
    "    return tflite_quant_model\n",
    "    \n",
    "#Float16 quantization function\n",
    "def float16_quant(model,modeltype):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    tflite_quant_model = converter.convert()\n",
    "    \n",
    "    quant_file_path = 'quant_models/float16'+modeltype+'.tflite'\n",
    "    with open(quant_file_path, 'wb') as f:\n",
    "        f.write(tflite_quant_model)\n",
    "\n",
    "    return tflite_quant_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load the image into memory and convert it to a TF Record. We convert to a TF Record to take advantage of efficiency gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = load_imgs('images/')\n",
    "dataset = Dataset.from_tensor_slices((imgs,labels)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate models and run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2 accuracy\n",
      "model accuracy is 83.9000% (Number of test samples=1000)\n",
      "ResNet50V2 accuracy\n",
      "model accuracy is 73.1000% (Number of test samples=1000)\n",
      "ResNet101V2 accuracy\n",
      "model accuracy is 76.7000% (Number of test samples=1000)\n",
      "ResNet152V2 accuracy\n",
      "model accuracy is 77.5000% (Number of test samples=1000)\n"
     ]
    }
   ],
   "source": [
    "m = generate_model('mobilenet')\n",
    "\n",
    "r50 = generate_model('resnet50')\n",
    "\n",
    "r101 = generate_model('resnet101')\n",
    "\n",
    "r152 = generate_model('resnet152')\n",
    "\n",
    "print('MobileNetV2 accuracy')\n",
    "testm = predict_class(dataset,m)\n",
    "accuracy(testm,labels)\n",
    "print('ResNet50V2 accuracy')\n",
    "testr50 = predict_class(dataset,r50)\n",
    "accuracy(testr50,labels)\n",
    "print('ResNet101V2 accuracy')\n",
    "testr101 = predict_class(dataset,r101)\n",
    "accuracy(testr101,labels)\n",
    "print('ResNet152V2 accuracy')\n",
    "testr152 = predict_class(dataset,r152)\n",
    "accuracy(testr152,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Range Quantization\n",
    "\n",
    "Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "mobiledynamic = dynamic_range_quant(m,'mobilenet')\n",
    "\n",
    "r50dynamic = dynamic_range_quant(r50,'resnet50')\n",
    "\n",
    "r101dynamic = dynamic_range_quant(r101,'resnet101')\n",
    "\n",
    "r152dynamic = dynamic_range_quant(r152,'resnet152')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dynamic Quantized MobileNetV2 accuracy')\n",
    "testm = evaluate_model(mobiledynamic)\n",
    "accuracy(testm,labels)\n",
    "print('Dynamic Quantized ResNet50V2 accuracy')\n",
    "testr50 = evaluate_model(r50dynamic)\n",
    "accuracy(testr50,labels)\n",
    "print('Dynamic Quantized ResNet101V2 accuracy')\n",
    "testr101 = evaluate_model(r101dynamic)\n",
    "accuracy(testr101,labels)\n",
    "print('Dynamic Quantized ResNet152V2 accuracy')\n",
    "testr152 = evaluate_model(r152dynamic)\n",
    "accuracy(testr152,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Integer Quantization\n",
    "\n",
    "Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauljojy/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "/Users/pauljojy/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "/Users/pauljojy/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "/Users/pauljojy/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "mobilefullint = full_int_quant(m, 'mobilenet')\n",
    "\n",
    "r50fullint = full_int_quant(r50, 'resnet50')\n",
    "\n",
    "r101fullint = full_int_quant(r101, 'resnet101')\n",
    "\n",
    "r152fullint = full_int_quant(r152, 'resnet152')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Integer Quantized MobileNetV2 accuracy\n",
      "model accuracy is 82.0000% (Number of test samples=1000)\n",
      "Full Integer Quantized ResNet50V2 accuracy\n",
      "model accuracy is 72.1000% (Number of test samples=1000)\n",
      "Full Integer Quantized ResNet101V2 accuracy\n",
      "model accuracy is 76.1000% (Number of test samples=1000)\n",
      "Full Integer Quantized ResNet152V2 accuracy\n"
     ]
    }
   ],
   "source": [
    "print('Full Integer Quantized MobileNetV2 accuracy')\n",
    "testm = evaluate_model(mobilefullint)\n",
    "accuracy(testm,labels)\n",
    "print('Full Integer Quantized ResNet50V2 accuracy')\n",
    "testr50 = evaluate_model(r50fullint)\n",
    "accuracy(testr50,labels)\n",
    "print('Full Integer Quantized ResNet101V2 accuracy')\n",
    "testr101 = evaluate_model(r101fullint)\n",
    "accuracy(testr101,labels)\n",
    "print('Full Integer Quantized ResNet152V2 accuracy')\n",
    "testr152 = evaluate_model(r152fullint)\n",
    "accuracy(testr152,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Float16 quantization\n",
    "\n",
    "Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "mobilefloat16 = float16_quant(m,'mobilenet')\n",
    "\n",
    "r50float16 = float16_quant(r50,'resnet50')\n",
    "\n",
    "r101float16 = float16_quant(r101,'resnet101')\n",
    "\n",
    "r152float16 = float16_quant(r152,'resnet152')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float16 Quantized MobileNetV2 accuracy\n",
      "model accuracy is 83.7000% (Number of test samples=1000)\n",
      "Float16 Quantized ResNet50V2 accuracy\n",
      "model accuracy is 73.0000% (Number of test samples=1000)\n",
      "Float16 Quantized ResNet101V2 accuracy\n",
      "model accuracy is 76.7000% (Number of test samples=1000)\n",
      "Float16 Quantized ResNet152V2 accuracy\n",
      "model accuracy is 77.5000% (Number of test samples=1000)\n"
     ]
    }
   ],
   "source": [
    "print('Float16 Quantized MobileNetV2 accuracy')\n",
    "testm = evaluate_model(mobilefloat16)\n",
    "accuracy(testm,labels)\n",
    "print('Float16 Quantized ResNet50V2 accuracy')\n",
    "testr50 = evaluate_model(r50float16)\n",
    "accuracy(testr50,labels)\n",
    "print('Float16 Quantized ResNet101V2 accuracy')\n",
    "testr101 = evaluate_model(r101float16)\n",
    "accuracy(testr101,labels)\n",
    "print('Float16 Quantized ResNet152V2 accuracy')\n",
    "testr152 = evaluate_model(r152float16)\n",
    "accuracy(testr152,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
